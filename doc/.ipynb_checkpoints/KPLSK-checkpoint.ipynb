{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:0caf97c7316e4bf9f45c2c6d06bab18d4a4b8c04e227fff371e63a28ac10bb5d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# KPLSK\n",
      "\n",
      "KPLSK is a [KPLS](./KPLS.html)-based model and is basically built in two steps.\n",
      "The first step consists in running KPLS and giving the estimate hyperparameters expressed in the reduced space with a number of dimensions equals to $q$.\n",
      "The second step consists in expressing the estimate hyperparameters in the original space with a number of dimensions equals to $d$, and then using it as a starting point to locally optimizing the likelihood function of a standard kriging.\n",
      "The idea here is guessing a \"good\" initial hyperparameters and applying a gradient-based optimization using a classic kriging-kernels.\n",
      "The \"good\" guess will be provided by KPLS: the solutions $\\left(\\theta_1^*,\\dots,\\theta_q^*\\right)$ and the PLS-coefficients $\\left(w_1^{(h)},\\dots,w_d^{(h)}\\right)$ for $h=1,\\dots,q$.\n",
      "By a change of variables $\\eta_i=\\sum_{h=1}^q\\theta_h^*{w^{(h)}_i}^2$, we can express the initial hyperparameters point in the original space.\n",
      "In the following example, a KPLS-Gaussian kernel function $k_{\\text{KPLS}}$ is used for the demonstration (More details are given in [1]):\n",
      "\\begin{equation}\n",
      "\\begin{array}{lll}\n",
      "k_{\\text{KPLS}}(x^{(u)},x^{(v)}) &=&\\sigma\\prod\\limits_{h=1}^q\\prod\\limits_{i=1}^d\\exp{\\left(-\\theta_h {w_i^{(h)}}^2\\left(x_i^{(u)}-x_i^{(v)}\\right)^2\\right)}\\\\\n",
      "&=&\\sigma\\exp\\left(\\sum\\limits_{i=1}^d\\sum\\limits_{h=1}^q-\\theta_h{w_i^{(h)}}^2\\left(x_i^{(u)}-x_i^{(v)}\\right)^2\\right)\\qquad \\text{Change of variables}\\\\\n",
      "&=&\\sigma\\exp\\left(\\sum\\limits_{i=1}^d-\\eta_i\\left(x_i^{(u)}-x_i^{(v)}\\right)^2\\right)\\\\\n",
      "&=&\\sigma\\prod\\limits_{i=1}^d\\exp\\left(-\\eta_i\\left(x_i^{(u)}-x_i^{(v)}\\right)^2\\right).\\\\\n",
      "\\end{array}\n",
      "\\end{equation}\n",
      "$\\prod\\limits_{i=1}^d\\exp\\left(-\\eta_i\\left(x_i^{(u)}-x_i^{(v)}\\right)^2\\right)$ is a standard Gaussian kernel function.\n",
      "\n",
      "Subsequently, the hyperparameters point $\\left(\\eta_1=\\sum_{h=1}^q\\theta_h^*{w^{(h)}_1}^2,\\dots,\\eta_d=\\sum_{h=1}^q\\theta_h^*{w^{(h)}_d}^2\\right)$ is used as a starting point for a gradient-based optimization applied on a standard kriging method.\n",
      "\n",
      "[1] Bouhlel, M. A., Bartoli, N., Otsmane, A., and Morlier, J., An Improved Approach for Estimating the Hyperparameters of the Kriging Model for High-Dimensional Problems through the Partial Least Squares Method,\" Mathematical Problems in Engineering, Vol. 2016, 2016.\n",
      "\n",
      "## Options\n",
      "\n",
      "| Option | Default | Acceptable values | Acceptable types | Description |\n",
      "| - | - | - | - | - |\n",
      "| n_comp | 1 | None | ['int'] | Number of principal components |\n",
      "| data_dir | None | None | ['str'] | Directory for loading / saving cached data; None means do not save or load |\n",
      "| print_solver | True | None | ['bool'] | Whether to print solver information |\n",
      "| print_problem | True | None | ['bool'] | Whether to print problem information |\n",
      "| print_global | True | None | ['bool'] | Global print toggle. If False, all printing is suppressed |\n",
      "| theta0 | [0.01] | None | ['list', 'ndarray'] | Initial hyperparameters |\n",
      "| poly | constant | ('constant', 'linear', 'quadratic') | ['function'] | regr. term |\n",
      "| corr | squar_exp | ('abs_exp', 'squar_exp') | ['function'] | type of corr. func. |\n",
      "| print_training | True | None | ['bool'] | Whether to print training information |\n",
      "| print_prediction | True | None | ['bool'] | Whether to print prediction information |\n",
      "\n",
      "## Example code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import numpy as np\n",
      "from smt.methods.kplsk import KPLSK\n",
      "from scipy import linalg\n",
      "from smt.problems import Sphere\n",
      "from smt.sampling import LHS\n",
      "\n",
      "\n",
      "# Initialization of the problem\n",
      "ndim = 10\n",
      "ndoe = int(10*ndim)\n",
      "\n",
      "# Define the function\n",
      "fun = Sphere(ndim = ndim)\n",
      "\n",
      "# Construction of the DOE\n",
      "sampling = LHS(xlimits=fun.xlimits,criterion = 'm')\n",
      "xt = sampling(ndoe)\n",
      "\n",
      "# Compute the output\n",
      "yt = fun(xt)\n",
      "# Compute the gradient\n",
      "for i in range(ndim):\n",
      "    yd = fun(xt,kx=i)\n",
      "    yt = np.concatenate((yt,yd),axis=1)\n",
      "\n",
      "# Construction of the validation points\n",
      "ntest = 500\n",
      "sampling = LHS(xlimits=fun.xlimits)\n",
      "xtest = sampling(ntest)\n",
      "ytest = fun(xtest)\n",
      "\n",
      "########### The KPLSK model\n",
      "# 'n_comp' and 'theta0' must be an integer in [1,ndim[ and a list of length n_comp, respectively.\n",
      "t = KPLSK(n_comp=2, theta0=[1e-2,1e-2])\n",
      "t.add_training_points('exact',xt,yt[:,0])\n",
      "t.train()\n",
      "y = t.predict_value(xtest)\n",
      "\n",
      "print('KPLSK,  err: '+str(linalg.norm(y.reshape((ntest,1))-ytest.reshape((ntest,\n",
      "            1)))/linalg.norm(ytest.reshape((ntest,1)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "___________________________________________________________________________\n",
        "   \n",
        "                                   KPLSK\n",
        "___________________________________________________________________________\n",
        "   \n",
        " Problem size\n",
        "   \n",
        "      # training points.        : 100\n",
        "   \n",
        "___________________________________________________________________________\n",
        "   \n",
        " Training\n",
        "   \n",
        "   Training ...\n",
        "   Training - done. Time (sec):  0.1273088\n",
        "___________________________________________________________________________\n",
        "   \n",
        " Evaluation\n",
        "   \n",
        "      # eval points. : 500\n",
        "   \n",
        "   Predicting ...\n",
        "   Predicting - done. Time (sec):  0.0099931\n",
        "   \n",
        "   Prediction time/pt. (sec) :  0.0000200\n",
        "   \n",
        "KPLSK,  err: 0.16988668972\n"
       ]
      }
     ],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}